{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAXjym-6H3Zi"
      },
      "source": [
        "# cs8321 Lab 2 - Transfer Learning and Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfzvDKYIH3Zj"
      },
      "source": [
        "#### Chip Henderson - 48996654"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cZzaCbH3Zj"
      },
      "source": [
        "## [2.0 points] Dataset Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgbHEjGRH3Zk"
      },
      "source": [
        "In this dataset, I'll be working on a sentiment classification. This is a many to one classifier of Amazon reviews. I'll be working with categories of negative, netral, and positive.\n",
        "\n",
        "Thhis version of the Amazon reviews dataset is was updated in 2018 from an original version in 2014. It consists of more than 230 million customer reviews from 1996 to 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNOBQmamH3Zk"
      },
      "source": [
        "**What is the feature data? Who collected the data? Why? When? Is it multimodal?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNjO5JzbH3Zk"
      },
      "source": [
        "**What evaluation criteria will you be using, why?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l01RLyJTH3Zk"
      },
      "source": [
        "## [2.0 points] Describe the foundational model that you will be using to transfer learn from"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfayZGDCH3Zk"
      },
      "source": [
        "I'll be using the bert-base-uncased model for my foundation model. This model's architecture consists of:\n",
        "* 12 layers\n",
        "* 768 hidden\n",
        "* 12-heads\n",
        "* 110 million parameters\n",
        "\n",
        "and trained on lower-cased English text per the [hugging face repo](https://huggingface.co/transformers/v3.3.1/pretrained_models.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UybHNh7H3Zk"
      },
      "source": [
        "**What tasks was the foundational model trained from?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYQ_iYspH3Zk"
      },
      "source": [
        "Per the hugging face [blog site](https://huggingface.co/google-bert/bert-base-uncased?text=The+goal+of+a+dog%27s+life+is+%5BMASK%5D), \"the BERT model was pretrained on BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia. It is also known as the Toronto Book Corpus, and consists of the text of around 7,000 self-published books scraped from the indie ebook distribution website Smashwords [per wikipedia](https://en.wikipedia.org/wiki/BookCorpus). The dataset consists of around 985 million words across a large span of genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLiY3K2BH3Zk"
      },
      "source": [
        "**Explain if the new task is within the same domain, across domains, etc.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "760cTIuaH3Zl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHsS5OABH3Zl"
      },
      "source": [
        "## [1.0 points] Split the data into training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkXRV9TjH3Zl"
      },
      "source": [
        "We'll start by importing the data from the source. I'll use a pandas dataframe initially due to its ease of understanding the labels and data types in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsTDbDGqJVFX",
        "outputId": "7a15ba05-dc27-496d-aaa4-1d6ce3187381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# # Uncomment for use in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /conent/drive/MyDrive/Colab Notebooks/mlenv7324.txt"
      ],
      "metadata": {
        "id": "WbvrzYe87FWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN02bwtkH3Zl",
        "outputId": "5f124d91-9b24-4e38-fa93-06c203aa308c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 7s, sys: 15 s, total: 2min 22s\n",
            "Wall time: 2min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Source: modified from https://nijianmo.github.io/amazon/index.html for\n",
        "# importing data. Customized path and df name\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "\n",
        "# path = \"../Data_sources/Electronics_5.json.gz\" # local\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Data_sources/Electronics_5.json.gz\" # colab\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "init_df = getDF(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "CFplCd0JH3Zm",
        "outputId": "03841286-ce32-4bc4-8100-f508424e3414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall vote  verified   reviewTime      reviewerID        asin  \\\n",
              "0      5.0   67      True  09 18, 1999   AAP7PPBU72QFM  0151004714   \n",
              "1      3.0    5      True  10 23, 2013  A2E168DTVGE6SV  0151004714   \n",
              "2      5.0    4     False   09 2, 2008  A1ER5AYS3FQ9O3  0151004714   \n",
              "3      5.0   13     False   09 4, 2000  A1T17LMQABMBN5  0151004714   \n",
              "4      3.0    8      True   02 4, 2000  A3QHJ0FXK33OBE  0151004714   \n",
              "\n",
              "                            style      reviewerName  \\\n",
              "0       {'Format:': ' Hardcover'}      D. C. Carrad   \n",
              "1  {'Format:': ' Kindle Edition'}               Evy   \n",
              "2       {'Format:': ' Paperback'}             Kcorn   \n",
              "3       {'Format:': ' Hardcover'}   Caf Girl Writes   \n",
              "4       {'Format:': ' Hardcover'}  W. Shane Schmidt   \n",
              "\n",
              "                                          reviewText  \\\n",
              "0  This is the best novel I have read in 2 or 3 y...   \n",
              "1  Pages and pages of introspection, in the style...   \n",
              "2  This is the kind of novel to read when you hav...   \n",
              "3  What gorgeous language! What an incredible wri...   \n",
              "4  I was taken in by reviews that compared this b...   \n",
              "\n",
              "                                             summary  unixReviewTime image  \n",
              "0                                     A star is born       937612800   NaN  \n",
              "1                    A stream of consciousness novel      1382486400   NaN  \n",
              "2  I'm a huge fan of the author and this one did ...      1220313600   NaN  \n",
              "3          The most beautiful book I have ever read!       968025600   NaN  \n",
              "4                        A dissenting view--In part.       949622400   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55e65fdc-763e-41cd-be3e-fa33d3aac209\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>67</td>\n",
              "      <td>True</td>\n",
              "      <td>09 18, 1999</td>\n",
              "      <td>AAP7PPBU72QFM</td>\n",
              "      <td>0151004714</td>\n",
              "      <td>{'Format:': ' Hardcover'}</td>\n",
              "      <td>D. C. Carrad</td>\n",
              "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
              "      <td>A star is born</td>\n",
              "      <td>937612800</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>10 23, 2013</td>\n",
              "      <td>A2E168DTVGE6SV</td>\n",
              "      <td>0151004714</td>\n",
              "      <td>{'Format:': ' Kindle Edition'}</td>\n",
              "      <td>Evy</td>\n",
              "      <td>Pages and pages of introspection, in the style...</td>\n",
              "      <td>A stream of consciousness novel</td>\n",
              "      <td>1382486400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>09 2, 2008</td>\n",
              "      <td>A1ER5AYS3FQ9O3</td>\n",
              "      <td>0151004714</td>\n",
              "      <td>{'Format:': ' Paperback'}</td>\n",
              "      <td>Kcorn</td>\n",
              "      <td>This is the kind of novel to read when you hav...</td>\n",
              "      <td>I'm a huge fan of the author and this one did ...</td>\n",
              "      <td>1220313600</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>09 4, 2000</td>\n",
              "      <td>A1T17LMQABMBN5</td>\n",
              "      <td>0151004714</td>\n",
              "      <td>{'Format:': ' Hardcover'}</td>\n",
              "      <td>Caf Girl Writes</td>\n",
              "      <td>What gorgeous language! What an incredible wri...</td>\n",
              "      <td>The most beautiful book I have ever read!</td>\n",
              "      <td>968025600</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "      <td>02 4, 2000</td>\n",
              "      <td>A3QHJ0FXK33OBE</td>\n",
              "      <td>0151004714</td>\n",
              "      <td>{'Format:': ' Hardcover'}</td>\n",
              "      <td>W. Shane Schmidt</td>\n",
              "      <td>I was taken in by reviews that compared this b...</td>\n",
              "      <td>A dissenting view--In part.</td>\n",
              "      <td>949622400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55e65fdc-763e-41cd-be3e-fa33d3aac209')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55e65fdc-763e-41cd-be3e-fa33d3aac209 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55e65fdc-763e-41cd-be3e-fa33d3aac209');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2cfd4d0-7546-4f43-ba4d-62bb1a62c3df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2cfd4d0-7546-4f43-ba4d-62bb1a62c3df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2cfd4d0-7546-4f43-ba4d-62bb1a62c3df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "init_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "init_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTuEI0kmH3Zm"
      },
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Du-sp65H3Zm"
      },
      "source": [
        "This is a big dataset, and there are a number of columns I don't need. To keep operations faster I'm going to drop everything I don't need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SsGntGwPH3Zm",
        "outputId": "546afb99-4323-4b07-ffbd-b1adb00e1f50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall                                         reviewText\n",
              "0      5.0  This is the best novel I have read in 2 or 3 y...\n",
              "1      3.0  Pages and pages of introspection, in the style...\n",
              "2      5.0  This is the kind of novel to read when you hav...\n",
              "3      5.0  What gorgeous language! What an incredible wri...\n",
              "4      3.0  I was taken in by reviews that compared this b..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a447e82-94d2-42cc-a9bd-5d529682c564\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Pages and pages of introspection, in the style...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>This is the kind of novel to read when you hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>What gorgeous language! What an incredible wri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>I was taken in by reviews that compared this b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a447e82-94d2-42cc-a9bd-5d529682c564')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a447e82-94d2-42cc-a9bd-5d529682c564 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a447e82-94d2-42cc-a9bd-5d529682c564');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acb786b4-50a2-4c6a-aca9-8bec188c578b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acb786b4-50a2-4c6a-aca9-8bec188c578b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acb786b4-50a2-4c6a-aca9-8bec188c578b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "features_to_keep = ['overall','reviewText']\n",
        "features_to_drop = [feature for feature in init_df.columns if feature not in features_to_keep]\n",
        "df = init_df.drop(features_to_drop,axis=1)\n",
        "\n",
        "del init_df # memory management\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joZi_rj9H3Zm",
        "outputId": "05823b7e-e1eb-498b-9be5-703f67aa8a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33698 entries, 0 to 33697\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   overall     33698 non-null  float64\n",
            " 1   reviewText  33691 non-null  object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 526.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# df = df.sample(frac=0.01,replace=False) # local\n",
        "df = df.sample(frac=0.005,replace=False) # local or colab\n",
        "\n",
        "# Colab could run 5% of the data but it completely maxed out the 51 GB of RAM\n",
        "# df = df.sample(frac=0.05,replace=False) # colab\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXlbq0HWH3Zm"
      },
      "source": [
        "I'm also going to remove any stop words from the review text. Stop words are words like \"a,” “the,” “is,” “are,\" and don't add a lot of contextual value. So they're a good way to reduce the size of the reviews. Before I can do that I need to make sure there aren't any unrecognized characters so I'll do some additional processing on the review text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OkD6qlDH3Zn",
        "outputId": "643e3497-3607-4ac9-8302-bbbb21f561b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33698 entries, 0 to 33697\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   overall         33698 non-null  float64\n",
            " 1   reviewText      33691 non-null  object \n",
            " 2   str_reviewText  33698 non-null  object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 789.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# The text of this dataset was an object datatype and wouldn't process as strings\n",
        "# So I'll need to convert it to a string\n",
        "df['reviewText'] = df['reviewText'].str.strip()\n",
        "df['str_reviewText'] = df['reviewText'].astype(str)\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZtC6natH3Zn",
        "outputId": "9f580e5f-9e0c-4175-ada8-129a5b92b5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        definitely expensive vast assortment low price...\n",
            "1                                             Good product\n",
            "2        I purchased Bose Speakers mounts costly Bose s...\n",
            "3        Update - longer able use, stopped working one ...\n",
            "4        I replaced mouse I dropped floor broke exact o...\n",
            "                               ...                        \n",
            "33693    If osmo, need this. There functional way attac...\n",
            "33694    Setup breeze, even though instructions said ho...\n",
            "33695    This well put together, quality picture amazin...\n",
            "33696    MINE CAME BROKEN AND I NEVER RETURNED THEM. TH...\n",
            "33697                                  We happy Ooma Telo.\n",
            "Name: str_reviewText, Length: 33698, dtype: object\n",
            "CPU times: user 1.11 s, sys: 868 ms, total: 1.98 s\n",
            "Wall time: 1.06 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Use NLTK to remove stopwords\n",
        "import nltk\n",
        "# import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stop_words(review):\n",
        "    # no_tags = re.sub(pattern,'',tweet)\n",
        "    no_stop_words = [word for word in review.split() if word not in stop_words]\n",
        "    return ' '.join(no_stop_words)\n",
        "\n",
        "\n",
        "# Apply the pattern to remove those tags from tweets\n",
        "df['str_reviewText'] = df['str_reviewText'].apply(remove_stop_words)\n",
        "df['reviewText'].drop\n",
        "\n",
        "print(df['str_reviewText'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd20GEygH3Zn"
      },
      "source": [
        "Strangely, these don't all seem like electronics reviews...but for my purposes it really doesn't matter. Also, there's no obvious sentiment labels in the dataset. So I'm going to use the overall rating as my sentiments. I'll set up the following categories:\n",
        " -  0-2: Negative\n",
        " -  3: Neutral\n",
        " -  4-5: Positive\n",
        "\n",
        "After grouping, I'll plot the distributions using a pie chart to visually observe how many samples are in each group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "PbloInReH3Zn",
        "outputId": "14e08780-7872-4968-d4b0-75c493759220"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bracket the sentiments based on Overall value\n",
        "df['sentiment'] = pd.cut(df['overall'], [0,2,3,5], labels=['negative','neutral','positive'])\n",
        "\n",
        "# Group the data by sentiment for purposes of charting\n",
        "sentiments = df.groupby(['sentiment'])\n",
        "pie_data = sentiments.size()\n",
        "\n",
        "# Set the pie chart parameters\n",
        "plt.pie(pie_data, labels=pie_data.index, autopct='%1.1f%%', labeldistance=1.1, startangle=90)\n",
        "\n",
        "plt.title(\"Quantity of Each Sentiment\")\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Get the exact count of each value to provide further information\n",
        "df.value_counts(['sentiment'])\n",
        "\n",
        "del sentiments # memory management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh1KREOPH3Zn"
      },
      "source": [
        "There is a significant misbalance of my classes, so I'm going to need to make sure I stratify the data so that the data is well represented. Before I do that, I'll tokenize the reviews and and prepare the data for splitting by narrowing down to fields of interest.\n",
        "\n",
        "To get started with tokenizing, I need to know the max length I'll encounter in the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhGv6ut4H3Zn",
        "outputId": "58d9ead3-ffef-4994-ca04-4c8637feac2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest review is 2231 words\n"
          ]
        }
      ],
      "source": [
        "# Determine longest review length\n",
        "# print(f\"The longest review is {len(max(df['str_reviewText'], key=len))} characters\")\n",
        "print(f\"The longest review is {max(len(review.split()) for review in df['str_reviewText'])} words\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgxadxMCH3Zo"
      },
      "source": [
        "In order for all the data going into the model to be same length, I'll need to zero-pad the sequences. For data consistency, I want all reviews to have some zero-padding. If my longest review length is 26,673 characters, I'll round up to 26,680 for my max length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo_BH8ZlH3Zo",
        "outputId": "00decba8-4063-4f0a-90f7-1a26e48ea97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 36725 unique tokens. Distilled to 36725 top words.\n",
            "Shape of data tensor: (33698, 2760)\n",
            "Shape of label tensor: (33698,)\n",
            "36725\n",
            "CPU times: user 3.74 s, sys: 217 ms, total: 3.96 s\n",
            "Wall time: 3.95 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Source: cs7324 lab 7\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "NUM_TOP_WORDS = None # use entire vocabulary!\n",
        "# MAX_REVIEW_LEN = 26680  # maximum and minimum number of words\n",
        "MAX_REVIEW_LEN = 2760\n",
        "\n",
        "#tokenize the text\n",
        "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
        "tokenizer.fit_on_texts(df['str_reviewText'])\n",
        "# save as sequences with integers replacing words\n",
        "sequences = tokenizer.texts_to_sequences(df['str_reviewText'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
        "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
        "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
        "\n",
        "X = pad_sequences(sequences, maxlen=MAX_REVIEW_LEN)\n",
        "y = df.sentiment.values\n",
        "print('Shape of data tensor:', X.shape)\n",
        "print('Shape of label tensor:', y.shape)\n",
        "print(np.max(X))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D9w4zUpmH3Zo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEPsnKT3qEB4",
        "outputId": "9628f20b-0856-46dd-88db-b1a91a646593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor train: (26958, 2760)\n",
            "Shape of data tensor for test: (6740, 2760)\n",
            "Shape of label tensor train: (26958, 3)\n",
            "Shape of label tensor for test: (6740, 3)\n"
          ]
        }
      ],
      "source": [
        "# Source: in class lecture notebook cs7324 13a\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "\n",
        "# Use label encoder to get my data into integer form\n",
        "label_encoder = LabelEncoder()\n",
        "y_enc_train = label_encoder.fit_transform(y_train)\n",
        "y_enc_test = label_encoder.fit_transform(y_test)\n",
        "\n",
        "# One-hot encode the encoded labels\n",
        "y_train_ohe = keras.utils.to_categorical(y_enc_train)\n",
        "y_test_ohe = keras.utils.to_categorical(y_enc_test)\n",
        "\n",
        "# Check the shape of the data and labels to ensure they are correct\n",
        "print('Shape of data tensor train:', X_train.shape)\n",
        "print('Shape of data tensor for test:', X_test.shape)\n",
        "print('Shape of label tensor train:', y_train_ohe.shape)\n",
        "print('Shape of label tensor for test:', y_test_ohe.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lY8WnXVH3Zo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2prjLIV3H3Zo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MhPiRGYH3Zp"
      },
      "source": [
        "**explain how you performed this operation and why you think it is reasonable to split this particular dataset this way**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Fe0vVKH3Zp"
      },
      "source": [
        "**For multi-task datasets, be sure to explain if it is appropriate to stratify within each task.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i90fmHulH3Zp"
      },
      "source": [
        "**If the dataset is already split for you, explain how the split was achieved and how it is stratified.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWftAZDfH3Zp"
      },
      "source": [
        "## [2.0 points] Train a model from scratch to perform the classification task (this does NOT need to be a transformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfsrVV76H3Zp"
      },
      "source": [
        "**Verify the model converges (even if the model is overfit).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5gceFPGH3Zq"
      },
      "source": [
        "#### Convolutional Neural Network 1 (CNN-1)\n",
        "\n",
        "The first CNN I'll run will consist of 64 filters with a width of 5. I'm changing the filter size from the in-class example because my dataset is quite a bit smaller. So my thought being I won't need so many filters to get good results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTvq6IlJaFKy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctQgoTDHaEkN",
        "outputId": "ba6baf5b-c89d-49d8-a9c2-b32f61053b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n",
            "Embedding Shape: (36726, 300) \n",
            " Total words found: 24325 \n",
            " Percentage: 66.2337308718619\n",
            "CPU times: user 22.3 s, sys: 877 ms, total: 23.2 s\n",
            "Wall time: 23.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Source: Modified from in-class lecture notebook 13a\n",
        "EMBED_SIZE = 300\n",
        "# the embed size should match the file you load glove from\n",
        "embeddings_index = {}\n",
        "# f = open(r'../Data_sources/glove.6B.300d.txt') # local\n",
        "f = open(r'/content/drive/MyDrive/Colab Notebooks/Data_sources/glove.6B.300d.txt') # colab\n",
        "# save key/array pairs of the embeddings\n",
        "#  the key of the dictionary is the word, the array is the embedding\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# now fill in the matrix, using the ordering from the\n",
        "#  keras word tokenizer from before\n",
        "found_words = 0\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be ALL-ZEROS\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        found_words = found_words+1\n",
        "\n",
        "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
        "    \"Total words found:\",found_words, \"\\n\",\n",
        "    \"Percentage:\",100*found_words/embedding_matrix.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bRd_DzxwjUVU"
      },
      "outputs": [],
      "source": [
        "# Source: Modified from in-class notebook 13a\n",
        "# save this embedding now\n",
        "from tensorflow.keras.layers import Embedding, Input, Concatenate\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBED_SIZE,\n",
        "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
        "                            input_length=MAX_REVIEW_LEN,\n",
        "                            trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nox7TH_PZm5G"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 3 # positive, negative, neutral\n",
        "EMBED_SIZE = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jr8K0dZmfRz",
        "outputId": "2d0167c4-1610-4151-969e-af67b225b1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 2760)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 2760, 300)    11017800    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 2756, 64)     96064       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 551, 64)      0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 551, 64)      0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 547, 64)      20544       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 109, 64)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 109, 64)      0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 105, 64)      20544       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d_2[0][0]']               \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " subtract (Subtract)            (None, 105, 64)      0           ['conv1d_2[0][0]',               \n",
            "                                                                  'global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " tf.math.pow (TFOpLambda)       (None, 105, 64)      0           ['subtract[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 64)          0           ['tf.math.pow[0][0]']            \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " concat_1 (Concatenate)         (None, 128)          0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 , 'global_average_pooling1d_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['concat_1[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            195         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,163,403\n",
            "Trainable params: 145,603\n",
            "Non-trainable params: 11,017,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "211/211 [==============================] - 244s 1s/step - loss: 0.6561 - precision: 0.8088 - val_loss: 0.6140 - val_precision: 0.8144\n",
            "Epoch 2/6\n",
            "211/211 [==============================] - 246s 1s/step - loss: 0.5762 - precision: 0.8252 - val_loss: 0.5731 - val_precision: 0.8593\n",
            "Epoch 3/6\n",
            "211/211 [==============================] - 247s 1s/step - loss: 0.5312 - precision: 0.8479 - val_loss: 0.5313 - val_precision: 0.8440\n",
            "Epoch 4/6\n",
            "211/211 [==============================] - 244s 1s/step - loss: 0.4999 - precision: 0.8606 - val_loss: 0.5235 - val_precision: 0.8502\n",
            "Epoch 5/6\n",
            "211/211 [==============================] - 241s 1s/step - loss: 0.4687 - precision: 0.8696 - val_loss: 0.5230 - val_precision: 0.8500\n",
            "Epoch 6/6\n",
            "211/211 [==============================] - 239s 1s/step - loss: 0.4396 - precision: 0.8802 - val_loss: 0.5435 - val_precision: 0.8440\n"
          ]
        }
      ],
      "source": [
        "# Source: Modified from in class notebook 13a\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Subtract\n",
        "\n",
        "\n",
        "EMBED_SIZE = 300  # same size as loaded from GLOVE\n",
        "sequence_input = Input(shape=(MAX_REVIEW_LEN,), dtype='int32')\n",
        "# starting size: 1000\n",
        "embedded_sequences = embedding_layer(sequence_input) # from previous embedding\n",
        "x = Conv1D(64, 5, activation='relu',\n",
        "        kernel_initializer='he_uniform')(embedded_sequences)\n",
        "\n",
        "# after conv, size becomes: 1000-4=996\n",
        "x = MaxPooling1D(5)(x)# after max pool, 996/5 = 199\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv1D(64, 5, activation='relu',\n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "# new size is 195\n",
        "x = MaxPooling1D(5)(x) # after max pool, size is 195/5 = 39\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv1D(64, 5, activation='relu',\n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "# after convolution, size becomes 15 elements long\n",
        "# Take the mean of these elements across features, result is 128 elements\n",
        "x_mean = GlobalAveragePooling1D()(x) # this is the size to globally flatten\n",
        "\n",
        "# Take the variance of these elements across features, result is 128 elements\n",
        "x_tmp = Subtract()([x,x_mean])\n",
        "x_std = GlobalAveragePooling1D()(x_tmp**2)\n",
        "\n",
        "x = Concatenate(name='concat_1')([x_mean,x_std])\n",
        "\n",
        "\n",
        "x = Dense(64, activation='relu',\n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "preds = Dense(NUM_CLASSES, activation='softmax',\n",
        "        kernel_initializer='glorot_uniform')(x)\n",
        "\n",
        "model_xvec = Model(sequence_input, preds)\n",
        "\n",
        "# if representing as OHE, use categorical_crossentropy\n",
        "# if representing the class as an integer, use sparse_categorical_crossentropy\n",
        "model_xvec.compile(loss='categorical_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['Precision'])\n",
        "\n",
        "print(model_xvec.summary())\n",
        "\n",
        "model_xvec_histories = []\n",
        "tmp = model_xvec.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe),\n",
        "        epochs=6, batch_size=128)\n",
        "model_xvec_histories.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d9VwJVa7aGxg"
      },
      "outputs": [],
      "source": [
        "# # Source: in class lecture notebook 13a\n",
        "\n",
        "# %matplotlib inline\n",
        "# # combine all the history from training together\n",
        "# combined = dict()\n",
        "# for key in ['precision','val_precision','loss','val_loss']:\n",
        "#   combined[key] = np.hstack([x.history[key] for x in model_xvec_histories])\n",
        "\n",
        "# # summarize history for precision\n",
        "# plt.figure(figsize=(15,5))\n",
        "# plt.subplot(121)\n",
        "# plt.plot(combined['precision'])\n",
        "# plt.plot(combined['val_precision'])\n",
        "# plt.title('model precision')\n",
        "# plt.ylabel('precision')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "# # summarize history for loss\n",
        "# plt.subplot(122)\n",
        "# plt.plot(combined['loss'])\n",
        "# plt.plot(combined['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx-qL71RH3Zq"
      },
      "source": [
        "## [2.0 points] Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gJzceTbzW9ah"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow_text # colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlxPP4LUZm5H"
      },
      "source": [
        "I'm going to be preprocessing the data again using the BERT Preprocessor layer to ensure I'm feeding the data in correctly to the BERT model. The BERT model is expecting special tokens in my dataset, [CLS] and [SEP]. So I'll be using the BERT preprocessor to do that.\n",
        "\n",
        "The majority of this code comes from an example on Kaggle: https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX3rRqX_Zm5I",
        "outputId": "88e7aed2-a08d-4b33-c7f9-a1ab232087b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6zVVoo3Zm5I"
      },
      "source": [
        "BERT requirements for input conifguration can be provided by a built in tokenizer class. It performs the following:\n",
        " -  Tokenize the text\n",
        " -  Add special tokens described above\n",
        " -  create token IDs\n",
        " -  Pad sequences\n",
        " -  Create attention masks for the padded tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DHRAacr3Zm5I"
      },
      "outputs": [],
      "source": [
        "# source: https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel\n",
        "# source: https://huggingface.co/transformers/v2.11.0/main_classes/tokenizer.html\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def bert_encode(data,maximum_length) :\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "\n",
        "  for i in range(len(data.str_reviewText)):\n",
        "      encoded = tokenizer.encode_plus( # built in huggingface class\n",
        "\n",
        "        data.str_reviewText[i],\n",
        "        add_special_tokens=True,\n",
        "        max_length=maximum_length,\n",
        "        truncation=True,\n",
        "        pad_to_max_length=True,\n",
        "\n",
        "        return_attention_mask=True,\n",
        "\n",
        "      )\n",
        "\n",
        "      input_ids.append(encoded['input_ids'])\n",
        "      attention_masks.append(encoded['attention_mask'])\n",
        "  return np.array(input_ids),np.array(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mw-H_berZm5I"
      },
      "outputs": [],
      "source": [
        "# Split my data at the top level so that I can have it in an un-encoded format for the BERT encoder\n",
        "df_bert = pd.concat([df.str_reviewText,df.sentiment], axis=1)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train, test = train_test_split(df_bert, test_size=0.2, random_state=42)\n",
        "# train = train.reset_index(drop=True,inplace=True)\n",
        "# test = test.reset_index(drop=True,inplace=True)\n",
        "# train = train.reset_index(drop=True)\n",
        "# test = test.reset_index(drop=True)\n",
        "# train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjqWg5hHZm5I",
        "outputId": "e46a2754-f24f-4f71-fbbf-96943285d530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# del df # memory management # temporary comment out\n",
        "train_input_ids,train_attention_masks = bert_encode(df_bert,512) # hard coding MAX_REVIEW_LENGTH for now\n",
        "# test_input_ids,test_attention_masks = bert_encode(test,26680) # hard coding MAX_REVIEW_LENGTH for now\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(df_bert.sentiment)\n",
        "labels_encoded_ohe = keras.utils.to_categorical(labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ion5pQf-xPD0",
        "outputId": "1765da89-a83f-47be-a4b3-c3d92bac0a26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The datatype of the train_input_ids is  {<class 'numpy.ndarray'>}\n",
            "The shape is  {(33698, 512)} \n",
            "\n",
            "The datatype of the train_attention_masks is  {<class 'numpy.ndarray'>}\n",
            "The shape is  {(33698, 512)} \n",
            "\n",
            "The datatype of the labels_encoded is  {<class 'numpy.ndarray'>}\n",
            "The shape is  {(33698, 3)} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"The datatype of the train_input_ids is \",{type(train_input_ids)})\n",
        "print(f\"The shape is \",{train_input_ids.shape}, \"\\n\")\n",
        "\n",
        "print(f\"The datatype of the train_attention_masks is \",{type(train_attention_masks)})\n",
        "print(f\"The shape is \",{train_attention_masks.shape}, \"\\n\")\n",
        "\n",
        "print(f\"The datatype of the labels_encoded is \",{type(labels_encoded_ohe)})\n",
        "print(f\"The shape is \",{labels_encoded_ohe.shape}, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.10.0 # colab only"
      ],
      "metadata": {
        "id": "aT8hPAbx4Tri",
        "outputId": "1a8d906b-72f0-4d8e-f823-496a6b48d127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.62.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.9.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.36.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KU0_nX4vZm5J",
        "outputId": "66c95813-5315-46d9-8b89-85455278ce26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.10.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_model(bert_model):\n",
        "  input_ids = tf.keras.layers.Input(shape=(512,),dtype='int32')\n",
        "  attention_masks = tf.keras.layers.Input(shape=(512,),dtype='int32')\n",
        "\n",
        "  bert_model.trainable = False\n",
        "\n",
        "  output = bert_model([input_ids,attention_masks])\n",
        "  output = output[1]\n",
        "  output = tf.keras.layers.Dense(64,activation='relu')(output)\n",
        "  output = tf.keras.layers.Dropout(0.2)(output)\n",
        "  output = tf.keras.layers.Dense(3,activation='softmax')(output)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz6lyhqkZm5J",
        "outputId": "54a73f4d-1e10-47c6-815a-aa7a8dc5af77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFBertModel, BertConfig\n",
        "\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJwLTd9oZm5J",
        "outputId": "e4552218-7085-417f-a9dc-dce0576b6058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_2[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_3[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           49216       ['tf_bert_model[0][1]']          \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)           (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            195         ['dropout_40[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,531,651\n",
            "Trainable params: 49,411\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model(bert_model)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd5UKvzDZm5J",
        "outputId": "fa4876dc-d035-43c3-e6ae-24355bb0293f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            " 20/211 [=>............................] - ETA: 4:07:51 - loss: 0.7402 - accuracy: 0.7715"
          ]
        }
      ],
      "source": [
        "bert_history = model.fit([train_input_ids,train_attention_masks],labels_encoded_ohe,validation_split=0.2, epochs=2,batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Y9dD28bm5l"
      },
      "outputs": [],
      "source": [
        "# Source: in class lecture notebook 13a\n",
        "%matplotlib inline\n",
        "\n",
        "# combine all the history from training together\n",
        "combined = dict()\n",
        "for key in ['precision','val_precision','loss','val_loss']:\n",
        "    combined[key] = np.hstack([x.history[key] for x in model_bert_histories])\n",
        "\n",
        "# summarize history for precision\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(combined['precision'])\n",
        "plt.plot(combined['val_precision'])\n",
        "plt.title('model precision')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(122)\n",
        "plt.plot(combined['loss'])\n",
        "plt.plot(combined['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t25vAx_H3Zq"
      },
      "source": [
        "**Train a model by transfer learning from your foundational model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-A4mRB4H3Zq"
      },
      "source": [
        "**Verify that the new model converges. You only need to train a model using the bottleneck features for this step.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C377UiG4H3Zq"
      },
      "source": [
        "## [2.0 points] Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuvIP3-gH3Zr"
      },
      "source": [
        "**Perform fine tuning upon the model by training some layers within the foundational model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGlYaFNlH3Zr"
      },
      "source": [
        "**Verify that the model converges.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH2cAUBCH3Zr"
      },
      "source": [
        "## [4.0 points] Report the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SUC_mSIH3Zr"
      },
      "source": [
        "**Report the results of all models using the evaluation procedure that you argued for at the beginning of the lab.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nazxUQlUH3Zr"
      },
      "source": [
        "**Compare the convergence of the models and the running time.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-FD2wYiH3Zr"
      },
      "source": [
        "**Results should be reported with proper statistical comparisons and proper visualizations.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUCw7rE8H3Zr"
      },
      "source": [
        "## Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w30SJfZH3Zr"
      },
      "outputs": [],
      "source": [
        "https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "https://keras.io/examples/nlp/pretraining_BERT/\n",
        "https://www.smashwords.com/about\n",
        "https://huggingface.co/google-bert/bert-base-uncased?text=The+goal+of+a+dog%27s+life+is+%5BMASK%5D.\n",
        "https://keras.io/guides/keras_nlp/transformer_pretraining/\n",
        "https://huggingface.co/transformers/v3.3.1/pretrained_models.html\n",
        "https://www.analyticsvidhya.com/blog/2021/05/all-you-need-to-know-about-bert/#:~:text=The%20BERTBase%20model%20uses,has%20around%20110M%20trainable%20parameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}