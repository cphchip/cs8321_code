{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAXjym-6H3Zi"
      },
      "source": [
        "# cs8321 Lab 2 - Transfer Learning and Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfzvDKYIH3Zj"
      },
      "source": [
        "#### Chip Henderson - 48996654"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cZzaCbH3Zj"
      },
      "source": [
        "## [2.0 points] Dataset Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgbHEjGRH3Zk"
      },
      "source": [
        "In this dataset, I'll be working on a sentiment classification. This is a many to one classifier of Amazon reviews. I'll be working with categories of negative, netral, and positive.\n",
        "\n",
        "Thhis version of the Amazon reviews dataset is was updated in 2018 from an original version in 2014. It consists of more than 230 million customer reviews from 1996 to 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNOBQmamH3Zk"
      },
      "source": [
        "**What is the feature data? Who collected the data? Why? When? Is it multimodal?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNjO5JzbH3Zk"
      },
      "source": [
        "**What evaluation criteria will you be using, why?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l01RLyJTH3Zk"
      },
      "source": [
        "## [2.0 points] Describe the foundational model that you will be using to transfer learn from"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfayZGDCH3Zk"
      },
      "source": [
        "I'll be using the bert-base-uncased model for my foundation model. This model's architecture consists of:\n",
        "* 12 layers\n",
        "* 768 hidden\n",
        "* 12-heads\n",
        "* 110 million parameters\n",
        "\n",
        "and trained on lower-cased English text per the [hugging face repo](https://huggingface.co/transformers/v3.3.1/pretrained_models.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UybHNh7H3Zk"
      },
      "source": [
        "**What tasks was the foundational model trained from?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYQ_iYspH3Zk"
      },
      "source": [
        "Per the hugging face [blog site](https://huggingface.co/google-bert/bert-base-uncased?text=The+goal+of+a+dog%27s+life+is+%5BMASK%5D), \"the BERT model was pretrained on BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia. It is also known as the Toronto Book Corpus, and consists of the text of around 7,000 self-published books scraped from the indie ebook distribution website Smashwords [per wikipedia](https://en.wikipedia.org/wiki/BookCorpus). The dataset consists of around 985 million words across a large span of genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLiY3K2BH3Zk"
      },
      "source": [
        "**Explain if the new task is within the same domain, across domains, etc.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "760cTIuaH3Zl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHsS5OABH3Zl"
      },
      "source": [
        "## [1.0 points] Split the data into training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkXRV9TjH3Zl"
      },
      "source": [
        "We'll start by importing the data from the source. I'll use a pandas dataframe initially due to its ease of understanding the labels and data types in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsTDbDGqJVFX",
        "outputId": "3b71fd33-b1f2-4c6b-a9f0-cbcc8b56182c"
      },
      "outputs": [],
      "source": [
        "# Uncomment for use in colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN02bwtkH3Zl",
        "outputId": "cc4dbf96-6470-4f4a-a369-2a69afe92d33"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 463. MiB for an array with shape (9, 6739590) and data type object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:23\u001b[0m\n",
            "File \u001b[1;32m<timed exec>:21\u001b[0m, in \u001b[0;36mgetDF\u001b[1;34m(path)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\frame.py:1760\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1756\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1757\u001b[0m     )\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1762\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\internals\\construction.py:153\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    150\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2142\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2140\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2142\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1829\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1826\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1827\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1829\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1830\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2272\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2270\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2272\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2275\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2304\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2301\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2303\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2304\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2305\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2307\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 463. MiB for an array with shape (9, 6739590) and data type object"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Source: modified from https://nijianmo.github.io/amazon/index.html for\n",
        "# importing data. Customized path and df name\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "\n",
        "path = \"../Data_sources/Electronics_5.json.gz\" # local\n",
        "# path = \"/content/drive/MyDrive/Colab Notebooks/Data_sources/Electronics_5.json.gz\" # colab\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "init_df = getDF(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "CFplCd0JH3Zm",
        "outputId": "f80a5367-2371-4311-aaf1-b9808219a657"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'init_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minit_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'init_df' is not defined"
          ]
        }
      ],
      "source": [
        "init_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTuEI0kmH3Zm"
      },
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Du-sp65H3Zm"
      },
      "source": [
        "This is a big dataset, and there are a number of columns I don't need. To keep operations faster I'm going to drop everything I don't need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SsGntGwPH3Zm",
        "outputId": "881d0317-78ff-4965-b1fd-d5b8ae466f75"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Pages and pages of introspection, in the style...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>This is the kind of novel to read when you hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>What gorgeous language! What an incredible wri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>I was taken in by reviews that compared this b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall                                         reviewText\n",
              "0      5.0  This is the best novel I have read in 2 or 3 y...\n",
              "1      3.0  Pages and pages of introspection, in the style...\n",
              "2      5.0  This is the kind of novel to read when you hav...\n",
              "3      5.0  What gorgeous language! What an incredible wri...\n",
              "4      3.0  I was taken in by reviews that compared this b..."
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_to_keep = ['overall','reviewText']\n",
        "features_to_drop = [feature for feature in init_df.columns if feature not in features_to_keep]\n",
        "df = init_df.drop(features_to_drop,axis=1)\n",
        "\n",
        "del init_df # memory management\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joZi_rj9H3Zm",
        "outputId": "37058601-c4ff-44c1-b594-8f5791a32263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33698 entries, 0 to 33697\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   overall     33698 non-null  float64\n",
            " 1   reviewText  33695 non-null  object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 526.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# df = df.sample(frac=0.01,replace=False) # local\n",
        "df = df.sample(frac=0.005,replace=False) # local\n",
        "\n",
        "# Colab could run 5% of the data but it completely maxed out the 51 GB of RAM\n",
        "# df = df.sample(frac=0.05,replace=False) # colab\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXlbq0HWH3Zm"
      },
      "source": [
        "I'm also going to remove any stop words from the review text. Stop words are words like \"a,” “the,” “is,” “are,\" and don't add a lot of contextual value. So they're a good way to reduce the size of the reviews. Before I can do that I need to make sure there aren't any unrecognized characters so I'll do some additional processing on the review text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OkD6qlDH3Zn",
        "outputId": "66015437-5e50-4d34-c6e8-b471a2403bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33698 entries, 0 to 33697\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   overall         33698 non-null  float64\n",
            " 1   reviewText      33695 non-null  object \n",
            " 2   str_reviewText  33698 non-null  object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 789.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# Note: Built in pandas functionality didn't seem to\n",
        "df['reviewText'] = df['reviewText'].str.strip()\n",
        "df['str_reviewText'] = df['reviewText'].astype(str)\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZtC6natH3Zn",
        "outputId": "4894308e-7923-492f-8789-bbcfdfde226e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Chip\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Chip\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        This good quality product; tested approved Nik...\n",
            "1        These okay, mini-USB port's casing large plug ...\n",
            "2        Must own! It's SUPER EASY use plug play diffic...\n",
            "3        This typical cheap, light plastic folio. Thisb...\n",
            "4                                                     good\n",
            "                               ...                        \n",
            "33693    At fraction price local big box & perform flaw...\n",
            "33694    Honestly can't beat price they're giving u, us...\n",
            "33695                          Well constructed. Reliable.\n",
            "33696    My wife burn distribute 100 CDs perfect additi...\n",
            "33697    I purchased cable connect laptop television, w...\n",
            "Name: str_reviewText, Length: 33698, dtype: object\n",
            "CPU times: total: 406 ms\n",
            "Wall time: 935 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Use NLTK to remove stopwords\n",
        "import nltk\n",
        "# import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stop_words(review):\n",
        "    # no_tags = re.sub(pattern,'',tweet)\n",
        "    no_stop_words = [word for word in review.split() if word not in stop_words]\n",
        "    return ' '.join(no_stop_words)\n",
        "\n",
        "\n",
        "# Apply the pattern to remove those tags from tweets\n",
        "df['str_reviewText'] = df['str_reviewText'].apply(remove_stop_words)\n",
        "\n",
        "print(df['str_reviewText'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd20GEygH3Zn"
      },
      "source": [
        "Strangely, these don't all seem like electronics reviews...but for my purposes it really doesn't matter. Also, there's no obvious sentiment labels in the dataset. So I'm going to use the overall rating as my sentiments. I'll set up the following categories:\n",
        " -  0-2: Negative\n",
        " -  3: Neutral\n",
        " -  4-5: Positive\n",
        "\n",
        "After grouping, I'll plot the distributions using a pie chart to visually observe how many samples are in each group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "PbloInReH3Zn",
        "outputId": "3b722fa4-ea09-4f5d-ec7d-4721fccf4241"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bracket the sentiments based on Overall value\n",
        "df['sentiment'] = pd.cut(df['overall'], [0,2,3,5], labels=['negative','neutral','positive'])\n",
        "\n",
        "# Group the data by sentiment for purposes of charting\n",
        "sentiments = df.groupby(['sentiment'])\n",
        "pie_data = sentiments.size()\n",
        "\n",
        "# Set the pie chart parameters\n",
        "plt.pie(pie_data, labels=pie_data.index, autopct='%1.1f%%', labeldistance=1.1, startangle=90)\n",
        "\n",
        "plt.title(\"Quantity of Each Sentiment\")\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Get the exact count of each value to provide further information\n",
        "df.value_counts(['sentiment'])\n",
        "\n",
        "del sentiments # memory management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh1KREOPH3Zn"
      },
      "source": [
        "There is a significant misbalance of my classes, so I'm going to need to make sure I stratify the data so that the data is well represented. Before I do that, I'll tokenize the reviews and and prepare the data for splitting by narrowing down to fields of interest.\n",
        "\n",
        "To get started with tokenizing, I need to know the max length I'll encounter in the reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhGv6ut4H3Zn",
        "outputId": "63d4994f-fa6c-4705-e4b2-102e022d80d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The longest review is 2755 words\n"
          ]
        }
      ],
      "source": [
        "# Determine longest review length\n",
        "# print(f\"The longest review is {len(max(df['str_reviewText'], key=len))} characters\")\n",
        "print(f\"The longest review is {max(len(review.split()) for review in df['str_reviewText'])} words\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgxadxMCH3Zo"
      },
      "source": [
        "In order for all the data going into the model to be same length, I'll need to zero-pad the sequences. For data consistency, I want all reviews to have some zero-padding. If my longest review length is 26,673 characters, I'll round up to 26,680 for my max length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo_BH8ZlH3Zo",
        "outputId": "94fd1741-ae98-47f7-ec60-4506764de60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 37338 unique tokens. Distilled to 37338 top words.\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 355. MiB for an array with shape (33698, 2760) and data type int32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:23\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\keras\\utils\\data_utils.py:1066\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_str:\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1061\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dtype` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not compatible with `value`\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms type: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1062\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou should set `dtype=object` for variable length \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1063\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1064\u001b[0m     )\n\u001b[1;32m-> 1066\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequences):\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s):\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\numpy\\core\\numeric.py:344\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    342\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m asarray(fill_value)\n\u001b[0;32m    343\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 344\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m multiarray\u001b[38;5;241m.\u001b[39mcopyto(a, fill_value, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 355. MiB for an array with shape (33698, 2760) and data type int32"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Source: cs7324 lab 7\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "NUM_TOP_WORDS = None # use entire vocabulary!\n",
        "# MAX_REVIEW_LEN = 26680  # maximum and minimum number of words\n",
        "MAX_REVIEW_LEN = 2760\n",
        "\n",
        "#tokenize the text\n",
        "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
        "tokenizer.fit_on_texts(df['str_reviewText'])\n",
        "# save as sequences with integers replacing words\n",
        "sequences = tokenizer.texts_to_sequences(df['str_reviewText'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
        "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
        "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
        "\n",
        "X = pad_sequences(sequences, maxlen=MAX_REVIEW_LEN)\n",
        "y = df.sentiment.values\n",
        "print('Shape of data tensor:', X.shape)\n",
        "print('Shape of label tensor:', y.shape)\n",
        "print(np.max(X))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "D9w4zUpmH3Zo",
        "outputId": "dcf4bf0c-5118-419e-9878-fdd2ecf6b3d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZEPsnKT3qEB4"
      },
      "outputs": [],
      "source": [
        "# Source: in class lecture notebook cs7324 13a\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "\n",
        "# Use label encoder to get my data into integer form\n",
        "label_encoder = LabelEncoder()\n",
        "y_enc_train = label_encoder.fit_transform(y_train)\n",
        "y_enc_test = label_encoder.fit_transform(y_test)\n",
        "\n",
        "# One-hot encode the encoded labels\n",
        "y_train_ohe = keras.utils.to_categorical(y_enc_train)\n",
        "y_test_ohe = keras.utils.to_categorical(y_enc_test)\n",
        "\n",
        "# Check the shape of the data and labels to ensure they are correct\n",
        "print('Shape of data tensor train:', X_train.shape)\n",
        "print('Shape of data tensor for test:', X_test.shape)\n",
        "print('Shape of label tensor train:', y_train_ohe.shape)\n",
        "print('Shape of label tensor for test:', y_test_ohe.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lY8WnXVH3Zo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2prjLIV3H3Zo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MhPiRGYH3Zp"
      },
      "source": [
        "**explain how you performed this operation and why you think it is reasonable to split this particular dataset this way**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Fe0vVKH3Zp"
      },
      "source": [
        "**For multi-task datasets, be sure to explain if it is appropriate to stratify within each task.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i90fmHulH3Zp"
      },
      "source": [
        "**If the dataset is already split for you, explain how the split was achieved and how it is stratified.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWftAZDfH3Zp"
      },
      "source": [
        "## [2.0 points] Train a model from scratch to perform the classification task (this does NOT need to be a transformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfsrVV76H3Zp"
      },
      "source": [
        "**Verify the model converges (even if the model is overfit).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5gceFPGH3Zq"
      },
      "source": [
        "#### Convolutional Neural Network 1 (CNN-1)\n",
        "\n",
        "The first CNN I'll run will consist of 64 filters with a width of 5. I'm changing the filter size from the in-class example because my dataset is quite a bit smaller. So my thought being I won't need so many filters to get good results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTvq6IlJaFKy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ctQgoTDHaEkN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Source: Modified from in-class lecture notebook 13a\n",
        "EMBED_SIZE = 300\n",
        "# the embed size should match the file you load glove from\n",
        "embeddings_index = {}\n",
        "f = open(r'../Data_sources/glove.6B.300d.txt') # local\n",
        "# f = open(r'/content/drive/MyDrive/Colab Notebooks/Data_sources/glove.6B.300d.txt') # colab\n",
        "# save key/array pairs of the embeddings\n",
        "#  the key of the dictionary is the word, the array is the embedding\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# now fill in the matrix, using the ordering from the\n",
        "#  keras word tokenizer from before\n",
        "found_words = 0\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be ALL-ZEROS\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        found_words = found_words+1\n",
        "\n",
        "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
        "    \"Total words found:\",found_words, \"\\n\",\n",
        "    \"Percentage:\",100*found_words/embedding_matrix.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bRd_DzxwjUVU"
      },
      "outputs": [],
      "source": [
        "# Source: Modified from in-class notebook 13a\n",
        "# save this embedding now\n",
        "from tensorflow.keras.layers import Embedding, Input, Concatenate\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBED_SIZE,\n",
        "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
        "                            input_length=MAX_REVIEW_LEN,\n",
        "                            trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_CLASSES = 3 # positive, negative, neutral\n",
        "EMBED_SIZE = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ikL1cOUPH3Zq"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "        # Source: Modified from in-class lecture, cs7324, notebook 13a\n",
        "        from tensorflow.keras.metrics import Precision\n",
        "        from tensorflow.keras.models import Model\n",
        "        from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
        "        from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "\n",
        "\n",
        "        EMBED_SIZE = 300  # same size as loaded from GLOVE\n",
        "        sequence_input = Input(shape=(MAX_REVIEW_LEN,), dtype='int32')\n",
        "        # starting size: 500\n",
        "        embedded_sequences = embedding_layer(sequence_input) # from previous embedding\n",
        "        x = Conv1D(64, 5, activation='relu',\n",
        "                kernel_initializer='he_uniform')(embedded_sequences)\n",
        "\n",
        "        # after conv, size becomes: 500-4=496\n",
        "        x = MaxPooling1D(5)(x) # after max pool, 996/5 = 99\n",
        "        x = Dropout(0.2)(x) # after dropout, size is 95\n",
        "        x = Conv1D(64, 5, activation='relu',\n",
        "                kernel_initializer='he_uniform')(x)\n",
        "\n",
        "        # new size is 195\n",
        "        x = MaxPooling1D(5)(x) # after max pool, size is 95/5 = 19\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv1D(64, 5, activation='relu',\n",
        "                kernel_initializer='he_uniform')(x)\n",
        "\n",
        "        # after convolution, size becomes 15 elements long\n",
        "        x = MaxPooling1D(5)(x) # this is the size to globally flatten, 15/5 = 3\n",
        "        # flattened vector max pools across each of the 3 elements\n",
        "        # so vectors is now 192 dimensions 3*64 = 192\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Dense(64, activation='relu',\n",
        "                kernel_initializer='he_uniform')(x)\n",
        "\n",
        "        preds = Dense(NUM_CLASSES, activation='softmax',\n",
        "                kernel_initializer='glorot_uniform')(x)\n",
        "\n",
        "        model_cnn_1 = Model(sequence_input, preds)\n",
        "\n",
        "        # if representing as OHE, use categorical_crossentropy\n",
        "        # if representing the class as an integer, use sparse_categorical_crossentropy\n",
        "        model_cnn_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer='rmsprop',\n",
        "                metrics=['Precision'])\n",
        "\n",
        "        print(model_cnn_1.summary())\n",
        "\n",
        "        cnn1_histories = []\n",
        "        tmp = model_cnn_1.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe),\n",
        "                epochs=30, batch_size=128)\n",
        "        cnn1_histories.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1jr8K0dZmfRz"
      },
      "outputs": [],
      "source": [
        "# Source: Modified from in class notebook 13a\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Subtract\n",
        "\n",
        "\n",
        "EMBED_SIZE = 300  # same size as loaded from GLOVE\n",
        "sequence_input = Input(shape=(MAX_REVIEW_LEN,), dtype='int32')\n",
        "# starting size: 1000\n",
        "embedded_sequences = embedding_layer(sequence_input) # from previous embedding\n",
        "x = Conv1D(64, 5, activation='relu',\n",
        "        kernel_initializer='he_uniform')(embedded_sequences)\n",
        "\n",
        "# after conv, size becomes: 1000-4=996\n",
        "x = MaxPooling1D(5)(x)# after max pool, 996/5 = 199\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv1D(64, 5, activation='relu',\n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "# new size is 195\n",
        "x = MaxPooling1D(5)(x) # after max pool, size is 195/5 = 39\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv1D(64, 5, activation='relu',\n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "# after convolution, size becomes 15 elements long\n",
        "# Take the mean of these elements across features, result is 128 elements\n",
        "x_mean = GlobalAveragePooling1D()(x) # this is the size to globally flatten\n",
        "\n",
        "# Take the variance of these elements across features, result is 128 elements\n",
        "x_tmp = Subtract()([x,x_mean])\n",
        "x_std = GlobalAveragePooling1D()(x_tmp**2)\n",
        "\n",
        "x = Concatenate(name='concat_1')([x_mean,x_std])\n",
        "\n",
        "\n",
        "x = Dense(64, activation='relu',\n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "preds = Dense(NUM_CLASSES, activation='softmax',\n",
        "        kernel_initializer='glorot_uniform')(x)\n",
        "\n",
        "model_xvec = Model(sequence_input, preds)\n",
        "\n",
        "# if representing as OHE, use categorical_crossentropy\n",
        "# if representing the class as an integer, use sparse_categorical_crossentropy\n",
        "model_xvec.compile(loss='categorical_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['Precision'])\n",
        "\n",
        "print(model_xvec.summary())\n",
        "\n",
        "model_xvec_histories = []\n",
        "tmp = model_xvec.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe),\n",
        "        epochs=6, batch_size=128)\n",
        "model_xvec_histories.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "d9VwJVa7aGxg"
      },
      "outputs": [],
      "source": [
        "# Source: in class lecture notebook 13a\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# combine all the history from training together\n",
        "combined = dict()\n",
        "for key in ['precision','val_precision','loss','val_loss']:\n",
        "    combined[key] = np.hstack([x.history[key] for x in model_xvec_histories])\n",
        "\n",
        "# summarize history for precision\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(combined['precision'])\n",
        "plt.plot(combined['val_precision'])\n",
        "plt.title('model precision')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(122)\n",
        "plt.plot(combined['loss'])\n",
        "plt.plot(combined['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx-qL71RH3Zq"
      },
      "source": [
        "## [2.0 points] Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzceTbzW9ah",
        "outputId": "cf12b020-0898-4433-d582-6a551f42127d"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow_text # colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I really like Stylus pens. They I expected be. I problems order.'\n",
            " \"I got ability use read cell phone SIM cards, I old cell phone who's SIM I wanted check out. I install Windows Mac able it, SIM reader work should. Everything else works fantastically out-of-the-box Mac, without need install drivers Windows anything. I like keep around laptop case case I come across esoteric, elderly card format nobody adapter for. Very good product!\"\n",
            " \"It quite fit Olympus Stylus TG-830 iHS. It's otherwise well-made attractive, little bit small.\"\n",
            " ...\n",
            " \"My wife kind enough pull Wish list order birthday. And disappointment. It's rather poorly finished. It silky smooth finish well made bamboo items that's quibble. The joining mechanism poorly designed case stay together falls iPad. Since actually putting iPad potential harm protecting, item returned. I would recommend case. I wish great option I know one.\"\n",
            " 'You get 6 full length cartridges mix colors $30...wow, $5 piece. Compare office supply store charges $24.99 ONE tape. These OEM (non Brother manufacturer) work well. Perfect replacement tape. Will definitely order again.'\n",
            " 'I looking notebooky-type thing complement immovable desktop computer, I often need computer things throughout day without able near desktop computer. I wanted something small, light, portable, affordable, actually worked. Voila! Enter ASUS 1000H! It arrived promptly well packaged essential things one might need. I box, booted, connected internet ten minutes. The entire computer seems quite well built I can\\'t see flaws workmanship. I much like runs XP opposed Vista. My desktop runs Vista always seemed quirky weird I\\'m never totally sure going next. The XP worked beautifully without single problem. It boots faster desktop. It get warm, like notebooks, uncomfortably hot lap. I upgraded RAM 2GB, finally figuring installing memory stick BIOS needed updated. It works well. There\\'s tons bloatware preinstalled, I\\'ve jettisoned stuff (namely Adobe) favor smaller, lighter freeware. It comes Microsoft Works Star Office, claim compatible Microsoft Office, although I totally tested yet. I\\'m using Windows Fileshare (free!) software sync documents pictures two computers. It works well easy keep files updated. As nearly everyone says, keyboard quite easy type on, actually pretty spacious. I\\'m total touch typist, well laid keyboard important. Nevertheless, right shift key driving crazy. I remapped today small piece software (also free!) called SharpKeys right shift page reversed. (I\\'ll switch key caps I figure remove without breaking them.) I\\'m dangerously fast typist machine. I get used typing without accidentally hitting trackpad, made cursor crazy things initially, learning curve particularly steep. Also, I get keyboard \"flex\" I hear about. The whole thing seems pretty sturdy me. I use wireless internet university complaints all. It always finds networks I single internet problem. I used Bluetooth, I Bluetooth devices, I can\\'t say works. I particularly care trackpad (the buttons stiff)and notebook mouse I prefer. I yet figured disable trackpad, I\\'ve doubt solution exists, somewhere. I nearly bought Lenovo S10, I liked specs, truthfully, I relieved ASUS 6 cell battery I constantly search electrical outlets. I Bluetooth permanently point, use wireless quite bit. I think I get 5 hours, conducted super scientific tests. Overall, machine works really well I need for: email, web surfing, word processing, etc. I think I\\'d try anything super fancy it, that\\'s desktop for. I\\'m really pleased far! Update (11/16/08): Just installed small piece software called Touch Freeze disables touchpad typing help avoid crazily jumping cursor typing. It works quite well I *really* type 1000H!']\n"
          ]
        }
      ],
      "source": [
        "print(df.str_reviewText.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I'm going to be preprocessing the data again using the BERT Preprocessor layer to ensure I'm feeding the data in correctly to the BERT model. The BERT model is expecting special tokens in my dataset, [CLS] and [SEP]. So I'll be using the BERT preprocessor to do that.\n",
        "\n",
        "The majority of this code comes from an example on Kaggle: https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tKEIITF0VLJ5",
        "outputId": "fd2f5ff2-abb3-464d-ca6b-db129639fff3"
      },
      "outputs": [],
      "source": [
        "# Source: modified from https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "# Source: Troubleshooting with ChatGPT\n",
        "# Source example gave dictionary of BERT model options, I'm directly selecting one\n",
        "\n",
        "if False: # this doesn't appear to be the right direction\n",
        "\n",
        "  import tensorflow as tf\n",
        "  import tensorflow_hub as hub\n",
        "  import tensorflow_text as text\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "  from tensorflow.keras.models import Model\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "  # Assuming you already have processed your data and have it in 'texts' and 'labels' lists\n",
        "  # 'texts' contains the preprocessed review text, 'labels' contains corresponding sentiment labels\n",
        "\n",
        "  # Encode labels\n",
        "  # label_encoder = LabelEncoder()\n",
        "  # labels_encoded = label_encoder.fit_transform(y)\n",
        "  num_classes = NUM_CLASSES\n",
        "\n",
        "  # # # Split data into training and testing sets\n",
        "  # # # train_texts, test_texts, train_labels, test_labels = train_test_split(df.str_reviewText.values, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Load BERT model from TensorFlow Hub\n",
        "  bert_model_name = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"  # Small BERT model\n",
        "  bert_preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "  bert_encoder = hub.KerasLayer(bert_model_name)\n",
        "\n",
        "  # Define input layer\n",
        "  input_layer = Input(shape=(MAX_REVIEW_LEN,), dtype='int32')\n",
        "\n",
        "  # BERT preprocessing and encoding\n",
        "  bert_preprocessed = bert_preprocessor(input_layer)\n",
        "  bert_encoded = bert_encoder(bert_preprocessed)\n",
        "\n",
        "  # # Dropout layer\n",
        "  dropout = Dropout(0.1)(bert_encoded)\n",
        "\n",
        "  # # Dense layer\n",
        "  dense = Dense(256, activation='relu')(dropout)\n",
        "\n",
        "  # # Output layer\n",
        "  output_layer = Dense(num_classes, activation='softmax')(dense)\n",
        "\n",
        "  # Define model\n",
        "  model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "              #   loss='sparse_categorical_crossentropy',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # # Train the model\n",
        "  model.fit(X_train, y_enc_train, validation_data=(X_test, y_enc_test),\n",
        "                  epochs=6, batch_size=128)\n",
        "\n",
        "  # # Evaluate the model\n",
        "  # loss, accuracy = model.evaluate(test_texts, test_labels)\n",
        "  # print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BERT requirements for input conifguration can be provided by a built in tokenizer class. It performs the following:\n",
        " -  Tokenize the text\n",
        " -  Add special tokens described above\n",
        " -  create token IDs\n",
        " -  Pad sequences\n",
        " -  Create attention masks for the padded tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# source: https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel\n",
        "# source: https://huggingface.co/transformers/v2.11.0/main_classes/tokenizer.html\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def bert_encode(data) :\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  \n",
        "\n",
        "  for i in range(len(data.str_reviewText)):\n",
        "      encoded = tokenizer.encode_plus( # built in huggingface class\n",
        "        \n",
        "        data.str_reviewText[i],\n",
        "        add_special_tokens=True,\n",
        "        truncation=512,\n",
        "        # max_length=maximum_length,\n",
        "        pad_to_max_length=True,\n",
        "        \n",
        "        return_attention_mask=True,\n",
        "        \n",
        "      )\n",
        "      \n",
        "      input_ids.append(encoded['input_ids'])\n",
        "      attention_masks.append(encoded['attention_mask'])\n",
        "  return np.array(input_ids),np.array(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split my data at the top level so that I can have it in an un-encoded format for the BERT encoder\n",
        "df_bert = pd.concat([df.str_reviewText,df.sentiment], axis=1)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train, test = train_test_split(df_bert, test_size=0.2, random_state=42)\n",
        "# train = train.reset_index(drop=True,inplace=True)\n",
        "# test = test.reset_index(drop=True,inplace=True)\n",
        "# train = train.reset_index(drop=True)\n",
        "# test = test.reset_index(drop=True)\n",
        "# train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "c:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "del df # memory management\n",
        "train_input_ids,train_attention_masks = bert_encode(df_bert) # hard coding MAX_REVIEW_LENGTH for now\n",
        "# test_input_ids,test_attention_masks = bert_encode(test,26680) # hard coding MAX_REVIEW_LENGTH for now\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(df_bert.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(33698, 2)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# debug\n",
        "df_bert.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def create_model(bert_model):\n",
        "  input_ids = tf.keras.Input(shape=(512,),dtype='int32')\n",
        "  attention_masks = tf.keras.Input(shape=(512,),dtype='int32')\n",
        "  \n",
        "  bert_model.trainable = False\n",
        "\n",
        "  output = bert_model([input_ids,attention_masks])\n",
        "  output = output[1]\n",
        "  output = tf.keras.layers.Dense(32,activation='relu')(output)\n",
        "  output = tf.keras.layers.Dropout(0.2)(output)\n",
        "  output = tf.keras.layers.Dense(1,activation='softmax')(output)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
        "  model.compile(Adam(lr=6e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFBertModel, BertConfig\n",
        "\n",
        "bert_model = TFBertModel.from_pretrained('bert-large-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  335141888   ['input_3[0][0]',                \n",
            "                                thPoolingAndCrossAt               'input_4[0][0]']                \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 1024),                                                           \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           32800       ['tf_bert_model_1[0][1]']        \n",
            "                                                                                                  \n",
            " dropout_147 (Dropout)          (None, 32)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            33          ['dropout_147[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 335,174,721\n",
            "Trainable params: 32,833\n",
            "Non-trainable params: 335,141,888\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model(bert_model)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  15/2696 [..............................] - ETA: 16:44:43 - loss: 0.0000e+00 - accuracy: 0.0933"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_attention_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\Chip\\anaconda3\\envs\\mlenv7324\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "bert_history = model.fit([train_input_ids,train_attention_masks],labels_encoded,validation_split=0.2, epochs=2,batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Y9dD28bm5l"
      },
      "outputs": [],
      "source": [
        "# Source: in class lecture notebook 13a\n",
        "%matplotlib inline\n",
        "\n",
        "# combine all the history from training together\n",
        "combined = dict()\n",
        "for key in ['precision','val_precision','loss','val_loss']:\n",
        "    combined[key] = np.hstack([x.history[key] for x in model_bert_histories])\n",
        "\n",
        "# summarize history for precision\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(combined['precision'])\n",
        "plt.plot(combined['val_precision'])\n",
        "plt.title('model precision')\n",
        "plt.ylabel('precision')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(122)\n",
        "plt.plot(combined['loss'])\n",
        "plt.plot(combined['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t25vAx_H3Zq"
      },
      "source": [
        "**Train a model by transfer learning from your foundational model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-A4mRB4H3Zq"
      },
      "source": [
        "**Verify that the new model converges. You only need to train a model using the bottleneck features for this step.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C377UiG4H3Zq"
      },
      "source": [
        "## [2.0 points] Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuvIP3-gH3Zr"
      },
      "source": [
        "**Perform fine tuning upon the model by training some layers within the foundational model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGlYaFNlH3Zr"
      },
      "source": [
        "**Verify that the model converges.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH2cAUBCH3Zr"
      },
      "source": [
        "## [4.0 points] Report the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SUC_mSIH3Zr"
      },
      "source": [
        "**Report the results of all models using the evaluation procedure that you argued for at the beginning of the lab.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nazxUQlUH3Zr"
      },
      "source": [
        "**Compare the convergence of the models and the running time.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-FD2wYiH3Zr"
      },
      "source": [
        "**Results should be reported with proper statistical comparisons and proper visualizations.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUCw7rE8H3Zr"
      },
      "source": [
        "## Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w30SJfZH3Zr"
      },
      "outputs": [],
      "source": [
        "https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "https://keras.io/examples/nlp/pretraining_BERT/\n",
        "https://www.smashwords.com/about\n",
        "https://huggingface.co/google-bert/bert-base-uncased?text=The+goal+of+a+dog%27s+life+is+%5BMASK%5D.\n",
        "https://keras.io/guides/keras_nlp/transformer_pretraining/\n",
        "https://huggingface.co/transformers/v3.3.1/pretrained_models.html\n",
        "https://www.analyticsvidhya.com/blog/2021/05/all-you-need-to-know-about-bert/#:~:text=The%20BERTBase%20model%20uses,has%20around%20110M%20trainable%20parameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
